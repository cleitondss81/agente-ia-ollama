ðŸ“Œ Agente de IA Local com Ollama + Mistral

Este projeto implementa um agente de IA totalmente local, utilizando:

âœ” Ollama (modelos locais)
âœ” Mistral como LLM
âœ” LangChain (LCEL)
âœ” Ferramenta integrada para executar comandos Linux

Ideal para automaÃ§Ã£o, estudo de agentes, DevOps e seguranÃ§a.

ðŸš€ Funcionalidades

IA rodando totalmente offline

ExecuÃ§Ã£o de comandos Linux via linguagem natural

Suporte ao modelo Mistral pelo Ollama

HistÃ³rico de conversa

Totalmente compatÃ­vel com LangChain moderno (2024+)

FÃ¡cil de estender com novas ferramentas

ðŸ§° Tecnologias Usadas

Python 3.12

LangChain

LangChain-Ollama

Ollama

Mistral LLM

LCEL (LangChain Expression Language)
